## **1、朴素贝叶斯（NaiveBayes）**

<b style='color:red'>分类算法</b>

朴素贝叶斯模型是基于概率论的原理，它的思想是这样的：对于给出的未知物体想要进行分类，就需要求解在这个未知物体出现的条件下各个类别出现的概率，哪个最大，就认为这个未知物体属于哪个分类。

## **2、SVM**

<b style='color:red'>分类算法</b>

SVM的中文叫支持向量机，英文是SupportVectorMachine，简称SVM。SVM在训练中建立了一个超平面的分类模型。

## **3、KNN**

<b style='color:red'>分类算法</b>

KNN也叫K最近邻算法，英文是K-NearestNeior。所谓K近邻，就是每个样本都可以用它最接近的K个邻居来代表。如果一个样本，它的K个最接近的邻居都属于分类A，那么这个样本也属于分类A。

## **4、AdaBoost**

Adaboost在训练中建立了一个联合的分类模型。boost在英文中代表提升的意思，所以Adaboost是个构建分类器的提升算法。它可以让我们多个弱的分类器组成一个强的分类器，所以Adaboost也是一个常用的分类算法。

## **5、CART**

CART代表分类和回归树，英文是ClassificationandRegressionTrees。像英文一样，它构建了两棵树：一棵是分类树，另一个是回归树。和、5一样，它是一个决策树学习方法。

## **6、Apriori**

Apriori是一种挖掘关联规则（associationrules）的算法，它通过挖掘频繁项集（frequentitemsets）来揭示物品之间的关联关系，被广泛应用到商业挖掘和网络安全等领域中。频繁项集是指经常出现在一起的物品的集合，关联规则暗示着两种物品之间可能存在很强的关系。

## **7、K-Means**

**聚类算法**

K-Means算法是一个聚类算法。你可以这么理解，最终我想把物体划分成K类。假设每个类别里面，都有个“中心点”，即意见领袖，它是这个类别的核心。现在我有一个新点要归类，这时候就只要计算这个新点与K个中心点的距离，距离哪个中心点近，就变成了哪个类别。

## **8、EM**

EM算法也叫最大期望算法，是求参数的最大似然估计的一种方法。原理是这样的：假设我们想要评估参数A和参数B，在开始状态下二者都是未知的，并且知道了A的信息就可以得到B的信息，反过来知道了B也就得到了A。可以考虑首先赋予A某个初值，以此得到B的估值，然后从B的估值出发，重新估计A的取值，这个过程一直持续到收敛为止。EM算法经常用于聚类和机器学习领域中。

## **9、PageRank**

PageRank起源于论文影响力的计算方式，如果一篇文论被引入的次数越多，就代表这篇论文的影响力越强。同样PageRank被Google创造性地应用到了网页权重的计算中：当一个页面链出的页面越多，说明这个页面的“参考文献”越多，当这个页面被链入的频率越高，说明这个页面被引用的次数越高。基于这个原理，我们可以得到网站的权重划分。

## **10、神经网络**

<b style='color:red'>分类算法</b>

**多层感知器（MLP）**：适用于复杂的非线性分类问题。
**卷积神经网络（CNN）**：在图像分类任务中具有出色的表现。


## 11、决策树

<b style='color:red'>分类算法</b>

**C4.5**：使用信息增益比来选择特征，适用于具有多个属性的分类问题。
**CART**：分类与回归树，可以同时处理分类和回归问题。


